{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **VGG网络 - 使用重复元素的网络**\n",
    "\n",
    "\n",
    "**参考文献：** [1] Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG的组成规律是：连续使用数个相同的填充为1、窗口形状为$3\\times 3$ 的卷积层后接上一个步幅为2、窗口形状为 $2\\times 2$ 的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import gluon,init,nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "def vgg_block(num_convs, num_channels):\n",
    "    blk = nn.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(nn.Conv2D(num_channels, kernel_size = 3,padding = 1, activation = 'relu'))\n",
    "        \n",
    "    blk.add(nn.MaxPool2D(pool_size = 2, strides = 2))        \n",
    "    return blk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与AlexNet、LeNet一样，VGG网络由卷积层模型后接全连接层模块构成。卷积层模块串联数个vgg_block，其超参数由变量conv_arch定义。该变量指定了每个VGG块里卷积层个数和输出通道数。全连接模块则与AlexNet一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造一个VGG网络。它有5个卷积块，前2块使用单卷积层，后3块使得双卷积层。 第1块输出通道是64，之后每次对输出通道翻倍，直到变为512。\n",
    "# 因为这个网络使用了8个卷积层和3个全连接层，所以常称为VGG-11\n",
    "conv_arch = ((1,64),(1,128),(2,256),(2,512),(2,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-11 实现\n",
    "\n",
    "def vgg(conv_arch):\n",
    "    net = nn.Sequential()\n",
    "    \n",
    "    # 卷积层部分\n",
    "    for (num_convs, num_channels) in conv_arch:\n",
    "        net.add(vgg_block(num_convs,num_channels))\n",
    "    # 全连接层\n",
    "    net.add(nn.Dense(4096, activation = 'relu'), nn.Dropout(0.5),\n",
    "            nn.Dense(4096, activation = 'relu'), nn.Dropout(0.5),\n",
    "            nn.Dense(10))\n",
    "    return net\n",
    "\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential1 output shsape:\t (1, 64, 112, 112)\n",
      "sequential2 output shsape:\t (1, 128, 56, 56)\n",
      "sequential3 output shsape:\t (1, 256, 28, 28)\n",
      "sequential4 output shsape:\t (1, 512, 14, 14)\n",
      "sequential5 output shsape:\t (1, 512, 7, 7)\n",
      "dense0 output shsape:\t (1, 4096)\n",
      "dropout0 output shsape:\t (1, 4096)\n",
      "dense1 output shsape:\t (1, 4096)\n",
      "dropout1 output shsape:\t (1, 4096)\n",
      "dense2 output shsape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# 构造一个高和宽均为224的单通道数据来观察每一层的输出形状\n",
    "net.initialize()\n",
    "X = nd.random.uniform(shape = (1,1,224,224))\n",
    "\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.name, \"output shsape:\\t\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 16), (1, 32), (2, 64), (2, 128), (2, 128)]\n"
     ]
    }
   ],
   "source": [
    "# 训练网络\n",
    "ratio = 4\n",
    "small_cov_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "print(small_cov_arch)\n",
    "\n",
    "net = vgg(small_cov_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size, ctx = 0.05, 5, 128, d2l.try_gpu()\n",
    "\n",
    "net.initialize(ctx = ctx, init = init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize = 224)\n",
    "d2l.train_ch5(net, train_iter , test_iter, batch_size, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
