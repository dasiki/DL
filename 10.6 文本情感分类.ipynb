{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "import d2lzh as d2l\n",
    "from mxnet import gluon,init,nd\n",
    "from mxnet.contrib import text\n",
    "from mxnet.gluon import data as gdata,loss as gloss,nn,rnn,utils as gutils\n",
    "import os \n",
    "import random\n",
    "import tarfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "\n",
    "def download_imdb(data_dir = \"../data/\"):\n",
    "    # url = (\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\")\n",
    "    # sha1 = \"01ada507287d82875905620988597833ad4e0903\"\n",
    "    # fname = gutils.download(url, data_dir, sha1_hash=sha1)\n",
    "    fname = \"../data/aclImdb_v1.tar.gz\"\n",
    "    \n",
    "    with tarfile.open(fname, 'r') as f:\n",
    "        f.extractall(data_dir)\n",
    "        \n",
    "download_imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练数据集和测试数据集；每个样本是一条评论以及其对应的标签：1：正面；0：负面\n",
    "def read_imdb(folder = 'train') :\n",
    "    data = []\n",
    "    for label in ['pos','neg']:\n",
    "        folder_name = os.path.join(\"../data/aclImdb/\",folder, label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode(\"utf-8\").replace(\"\\n\",\"\").lower()\n",
    "                data.append([review ,1 if label == 'pos' else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "        \n",
    "train_data,test_data = read_imdb(\"train\"),read_imdb(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('# words in vocab:', 46152)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预处理数据\n",
    "\n",
    "def get_tokenized_imdb(data): \n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(\" \")]\n",
    "    return [tokenizer(review) for review,_ in data]\n",
    "\n",
    "# 创建词典\n",
    "def get_vocab_imdb(data):\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return text.vocab.Vocabulary(counter, min_freq = 5, reserved_tokens = ['<pad>'])\n",
    "\n",
    "vocab = get_vocab_imdb(train_data)\n",
    "\n",
    "'# words in vocab:', len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于每条评论长度不一，不以直接组合成小批量\n",
    "# 通过词典转换成词索引，然后通过截断或补 '<pad>' (padding) 符号来将每条评论长度固定为500\n",
    "\n",
    "def preprocess_imdb(data,vocab):\n",
    "    max_l = 500 \n",
    "    \n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x)>max_l else x + [vocab.token_to_idx['<pad>']] * (max_l - len(x))\n",
    "    \n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    features = nd.array([pad(vocab.to_indices(x)) for x in tokenized_data])\n",
    "    labels = nd.array([score for _,score in data])\n",
    "    \n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据迭代器，每次迭代一个小批量的数据\n",
    "batch_size = 64\n",
    "train_set = gdata.ArrayDataset(*preprocess_imdb(train_data,vocab))\n",
    "test_set = gdata.ArrayDataset(*preprocess_imdb(test_data, vocab))\n",
    "train_iter = gdata.DataLoader(train_set, batch_size, shuffle = True)\n",
    "test_iter = gdata.DataLoader(test_set, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (64, 500) y (64,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('# batches:', 391)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X,y in train_iter:\n",
    "    print(\"X\",X.shape, \"y\",y.shape)\n",
    "    break\n",
    "    \n",
    "\"# batches:\",len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
